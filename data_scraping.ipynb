{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the pages with restaurants in New York\n",
    "ny_response = requests.get('https://www.yelp.com/search?find_desc=Restaurants&find_loc=New+York%2C+NY&ns=1')\n",
    "ny_results = BeautifulSoup(ny_response.content,'html')\n",
    "ny_pagenum = ny_results.find('div', {'role':\"navigation\"}).find('span', {'class':\n",
    "    \"lemon--span__373c0__3997G text__373c0__2pB8f text-color--inherit__373c0__w_15m text-align--left__373c0__2pnx_\"}).text[10:]\n",
    "ny_url = []\n",
    "for i in range(int(ny_pagenum)):\n",
    "    ny_url.append('https://www.yelp.com/search?find_desc=Restaurants&find_loc=New%20York%2C%20NY&ns=1%3Fstart%3D960' + f'&start={30*i}')\n",
    "\n",
    "# get each restaurant's link\n",
    "res_link = []\n",
    "for i in ny_url[:5]:\n",
    "    payload = {'api_key': '74eed888a9a7e4d48e3e2646387e3e97', 'url': i}\n",
    "    page_response = requests.get('http://api.scraperapi.com', params = payload)\n",
    "    try:\n",
    "        page_response.status_code == 200\n",
    "        print(\"Scraping success\")\n",
    "        page_results = BeautifulSoup(page_response.content,'html')\n",
    "            \n",
    "        meta = page_results.find('meta', {'property': 'og:description'}) # get each page's restaurants' name\n",
    "        res_list = meta.attrs['content'].split('NY - ')[1].split(',')\n",
    "\n",
    "        res_all = []\n",
    "        for j in res_list:\n",
    "            res_all.append(j.strip().replace('\\'','â€™'))\n",
    "        for l in res_all:\n",
    "            res_link.append((l, url + page_results.find('a', {'name':\"%s\"%(l)}).get('href')))\n",
    "    except:\n",
    "        print(\"Scraping error\")\n",
    "\n",
    "# define get recommended review function\n",
    "def get_review(res_link: list):\n",
    "    reviews = []\n",
    "    for item in res_link:\n",
    "        review = []\n",
    "        name = item[0]\n",
    "        link = item[1]\n",
    "        payload = {'api_key': '74eed888a9a7e4d48e3e2646387e3e97', 'url': link}\n",
    "        res_response = requests.get('http://api.scraperapi.com', params = payload)\n",
    "        try:\n",
    "            res_response.status_code == 200\n",
    "            print(\"Outside scraping success\")\n",
    "            res_results = BeautifulSoup(res_response.content,'html')\n",
    "\n",
    "            review.extend(json.loads(res_results.find('script', {'type':\"application/ld+json\"}).text)['review']) # get 1st page review\n",
    "\n",
    "            res_pagenum = res_results.find('div',{'role':\"navigation\"}).find('span', {'class': \n",
    "                    \"lemon--span__373c0__3997G text__373c0__2pB8f text-color--inherit__373c0__w_15m text-align--left__373c0__2pnx_\"}).get_text()[10:]\n",
    "            if res_pagenum != 1:   \n",
    "                review_link = []\n",
    "                for i in range(1,int(res_pagenum)):\n",
    "                    review_link.append('https://www.yelp.com/biz/am%C3%A9lie-new-york?osq=Restaurants' + f'&start={20*i}') # get the remaining review pages' links\n",
    "                for j in review_link:\n",
    "                    payload = {'api_key': '74eed888a9a7e4d48e3e2646387e3e97', 'url': j}\n",
    "                    next_res_response = requests.get('http://api.scraperapi.com', params = payload)\n",
    "                    try:\n",
    "                        next_res_response.status_code == 200\n",
    "                        print('Inside scraping success')\n",
    "                        next_res_results = BeautifulSoup(next_res_response.content,'html')\n",
    "                        review.extend(json.loads(next_res_results.find('script', {'type':\"application/ld+json\"}).text)['review'])\n",
    "                        max_num = str((int(res_pagenum)-1)*20)\n",
    "                        if max_num in j:\n",
    "                            break\n",
    "                        if len(review) >= 200: # scrap 200 reviews of each restaurant\n",
    "                            break\n",
    "                    except:\n",
    "                        print(\"Inside scraping error\")\n",
    "                        raise\n",
    "            else:\n",
    "                pass\n",
    "            for l in review:\n",
    "                    l['reviewRating'] = l['reviewRating']['ratingValue']\n",
    "                    l['businessName'] = name\n",
    "            reviews.extend(review)\n",
    "        except:\n",
    "            print(\"Outside scraping error\")\n",
    "            raise\n",
    "    return reviews\n",
    "\n",
    "# get all the recommended reviews\n",
    "get_review(res_link)\n",
    "\n",
    "# convert them into dataframe\n",
    "df = pd.DataFrame(recommended_review)\n",
    "df['label'] = 1 # set these reviews as true reviews\n",
    "df.columns = ['rating', 'date', 'review', 'author', 'business_name', 'label']\n",
    "\n",
    "# not recommended review scraping is following the same algorithms\n",
    "# the only difference is the links and the attributes of data in web pages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
